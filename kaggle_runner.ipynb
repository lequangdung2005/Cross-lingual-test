{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9c0591",
   "metadata": {},
   "source": [
    "# Few-Shot Test Generation Pipeline - Kaggle Runner\n",
    "\n",
    "This notebook clones the Cross-lingual-test repository and runs the few-shot test generation pipeline with different embedding models.\n",
    "\n",
    "**Requirements:**\n",
    "- GPU Runtime (recommended for faster embedding)\n",
    "- Internet enabled for cloning repo and downloading models\n",
    "\n",
    "**Models to test:**\n",
    "1. microsoft/unixcoder-base (768 dim)\n",
    "2. Salesforce/SFR-Embedding-Code-400M_R (larger, potentially better)\n",
    "3. sentence-transformers/all-MiniLM-L6-v2 (smaller, faster)\n",
    "4. microsoft/codebert-base (768 dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe6db9",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee799e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac95865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/lequangdung2005/Cross-lingual-test.git\n",
    "%cd Cross-lingual-test/Few_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install -q transformers datasets sentence-transformers torch tqdm numpy scikit-learn faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da11f1d",
   "metadata": {},
   "source": [
    "## Step 2: Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49424e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2f651",
   "metadata": {},
   "source": [
    "## Step 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# List of embedding models to test\n",
    "EMBEDDING_MODELS = [\n",
    "    \"microsoft/unixcoder-base\",\n",
    "    \"Salesforce/SFR-Embedding-Code-400M_R\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"microsoft/codebert-base\"\n",
    "]\n",
    "\n",
    "# You can modify these settings\n",
    "TOP_K = 3  # Number of final examples to return after reranking\n",
    "RERANK_POOL_SIZE = 50  # Number of candidates to retrieve before reranking\n",
    "SIMILARITY_THRESHOLD = 0.0  # Minimum similarity threshold (0.0 = no filtering)\n",
    "MAX_EXAMPLES = None  # Set to a number (e.g., 5000) for quick testing, None for all\n",
    "\n",
    "# Output directory for results\n",
    "OUTPUT_BASE = \"/kaggle/working/few_shot_outputs\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14b5f5",
   "metadata": {},
   "source": [
    "## Step 4: Run Test Runner for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bccbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Store results summary\n",
    "results_summary = []\n",
    "\n",
    "for i, model_name in enumerate(EMBEDDING_MODELS, 1):\n",
    "    print(f\"\\nProcessing model {i}/{len(EMBEDDING_MODELS)}: {model_name}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Build command with rerank pool size\n",
    "    cmd = f\"python test_runner.py --embedder '{model_name}' --top-k {TOP_K} --rerank-pool-size {RERANK_POOL_SIZE} --similarity-threshold {SIMILARITY_THRESHOLD}\"\n",
    "    if MAX_EXAMPLES:\n",
    "        cmd += f\" --max-examples {MAX_EXAMPLES}\"\n",
    "    \n",
    "    # Run the script\n",
    "    return_code = os.system(cmd)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Record results\n",
    "    result = {\n",
    "        \"model\": model_name,\n",
    "        \"success\": return_code == 0,\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    results_summary.append(result)\n",
    "    \n",
    "    status = \"✓\" if return_code == 0 else \"✗\"\n",
    "    print(f\"{status} Completed in {elapsed_time:.2f}s\")\n",
    "\n",
    "print(\"\\nAll models processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013556e",
   "metadata": {},
   "source": [
    "## Step 5: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca37614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary DataFrame\n",
    "df_summary = pd.DataFrame(results_summary)\n",
    "df_summary['elapsed_time_min'] = df_summary['elapsed_time'] / 60\n",
    "\n",
    "print(\"\\nEXECUTION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(df_summary[['model', 'success', 'elapsed_time_min']].to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Total: {len(results_summary)} | Successful: {sum(1 for r in results_summary if r['success'])} | Failed: {sum(1 for r in results_summary if not r['success'])}\")\n",
    "print(f\"Total time: {sum(r['elapsed_time'] for r in results_summary) / 60:.2f} minutes\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1eca60",
   "metadata": {},
   "source": [
    "## Step 6: Check Generated Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check generated prompt files\n",
    "import glob\n",
    "\n",
    "prompt_dir = \"src/data/constructed_prompt\"\n",
    "if os.path.exists(prompt_dir):\n",
    "    print(\"Generated Few-Shot Prompt Files:\\n\")\n",
    "    for model_name in EMBEDDING_MODELS:\n",
    "        model_short = model_name.replace('/', '_')\n",
    "        print(f\"\\n{model_name}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for lang in ['rust', 'go', 'julia']:\n",
    "            file_path = f\"{prompt_dir}/{model_name}/{lang}/data_with_fewshot.jsonl\"\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'r') as f:\n",
    "                    line_count = sum(1 for _ in f)\n",
    "                file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
    "                print(f\"  {lang.upper():6s}: {line_count:4d} prompts, {file_size:.2f} MB\")\n",
    "            else:\n",
    "                print(f\"  {lang.upper():6s}: Not found\")\n",
    "else:\n",
    "    print(f\"Prompt directory not found: {prompt_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4437b",
   "metadata": {},
   "source": [
    "## Step 7: Check Database Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a015be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check database files\n",
    "db_dir = \"src/data/database\"\n",
    "if os.path.exists(db_dir):\n",
    "    print(\"Generated Database Index Files:\\n\")\n",
    "    for model_name in EMBEDDING_MODELS:\n",
    "        db_path = f\"{db_dir}/{model_name}/database_index.pkl\"\n",
    "        if os.path.exists(db_path):\n",
    "            file_size = os.path.getsize(db_path) / (1024 * 1024)  # MB\n",
    "            print(f\"✓ {model_name}: {file_size:.2f} MB\")\n",
    "        else:\n",
    "            print(f\"✗ {model_name}: Not found\")\n",
    "else:\n",
    "    print(f\"Database directory not found: {db_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613342d7",
   "metadata": {},
   "source": [
    "## Step 8: Sample Output Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Show a sample prompt from the first successful model\n",
    "for model_name in EMBEDDING_MODELS:\n",
    "    sample_file = f\"src/data/constructed_prompt/{model_name}/rust/data_with_fewshot.jsonl\"\n",
    "    if os.path.exists(sample_file):\n",
    "        print(f\"Sample Few-Shot Prompt from {model_name}:\\n\")\n",
    "        print(\"=\" * 80)\n",
    "        with open(sample_file, 'r') as f:\n",
    "            first_line = f.readline()\n",
    "            sample = json.loads(first_line)\n",
    "            \n",
    "            print(f\"Case ID: {sample['id']}\")\n",
    "            print(f\"Retrieved Context Keys: {list(sample['retrieved_context'].keys())}\")\n",
    "            \n",
    "            # Show focal method (truncated)\n",
    "            focal = sample['retrieved_context'].get('focal_method', 'N/A')\n",
    "            print(f\"\\nFocal Method (first 300 chars):\\n{focal[:300]}...\")\n",
    "            \n",
    "            # Show number of retrieved examples\n",
    "            results = sample['retrieved_context'].get('results', [])\n",
    "            print(f\"\\nNumber of retrieved examples: {len(results)}\")\n",
    "            \n",
    "            if results:\n",
    "                print(f\"\\nFirst retrieved example (truncated):\")\n",
    "                first_result = results[0]\n",
    "                print(f\"  Similarity: {first_result.get('similarity', 'N/A')}\")\n",
    "                example_code = first_result.get('example', {}).get('focal_method', 'N/A')\n",
    "                print(f\"  Code: {example_code[:200]}...\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        break  # Only show first successful model\n",
    "else:\n",
    "    print(\"No sample files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ef209",
   "metadata": {},
   "source": [
    "## Step 9: Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aad14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file of all generated prompts for download\n",
    "import shutil\n",
    "\n",
    "output_zip = \"/kaggle/working/few_shot_prompts.zip\"\n",
    "prompt_dir = \"src/data/constructed_prompt\"\n",
    "\n",
    "if os.path.exists(prompt_dir):\n",
    "    shutil.make_archive(\n",
    "        output_zip.replace('.zip', ''),\n",
    "        'zip',\n",
    "        prompt_dir\n",
    "    )\n",
    "    \n",
    "    zip_size = os.path.getsize(output_zip) / (1024 * 1024)  # MB\n",
    "    print(f\"✓ Created {output_zip} ({zip_size:.2f} MB)\")\n",
    "    print(\"Download from Kaggle output panel.\")\n",
    "else:\n",
    "    print(f\"Prompt directory not found: {prompt_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b32bc",
   "metadata": {},
   "source": [
    "## Step 10: Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280aadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up large database files to save space\n",
    "# Uncomment the following lines if you want to remove database files\n",
    "\n",
    "# import shutil\n",
    "# db_dir = \"src/data/database\"\n",
    "# if os.path.exists(db_dir):\n",
    "#     shutil.rmtree(db_dir)\n",
    "#     print(\"✓ Database files removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad2f11",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "**Expected Runtime:**\n",
    "- Each model takes approximately 10-30 minutes depending on:\n",
    "  - Model size\n",
    "  - Number of training examples\n",
    "  - GPU availability\n",
    "  - Dataset size\n",
    "\n",
    "**Output Structure:**\n",
    "```\n",
    "src/data/\n",
    "├── constructed_prompt/\n",
    "│   ├── microsoft/unixcoder-base/\n",
    "│   │   ├── rust/data_with_fewshot.jsonl\n",
    "│   │   ├── go/data_with_fewshot.jsonl\n",
    "│   │   └── julia/data_with_fewshot.jsonl\n",
    "│   └── [other models]/\n",
    "└── database/\n",
    "    ├── microsoft/unixcoder-base/database_index.pkl\n",
    "    └── [other models]/database_index.pkl\n",
    "```\n",
    "\n",
    "**Troubleshooting:**\n",
    "- If a model fails to load, it may be too large for available memory\n",
    "- Try setting `MAX_EXAMPLES` to a smaller number (e.g., 5000) for testing\n",
    "- Ensure GPU runtime is enabled for faster processing\n",
    "- Check that internet is enabled for downloading models and datasets"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
