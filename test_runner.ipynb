{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25590e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "logger = logging.getLogger(__name__)\n",
    "from src.core.factory import RetrieverFactory\n",
    "from src.core.base import CodeExample\n",
    "from src.retrievers.dense.database import CodeExampleDatabase\n",
    "\n",
    "# Configuration\n",
    "TRAINING_DATA_PATH = \"src/data/database/high-resource/method2test/reformat_test.jsonl\"\n",
    "BENCHMARK_REPO = \"Tessera2025/Tessera2025\"\n",
    "OUTPUT_DIR = \"src/data/constructed_prompt\"\n",
    "DATABASE_SAVE_PATH = \"src/data/database/unixcoder/database_index.pkl\"\n",
    "EMBEDDER_NAME=\"unixcoder\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc2b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=datasets.load_dataset(BENCHMARK_REPO,trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0350dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _register_builtin_implementations():\n",
    "    \"\"\"Register built-in retriever implementations.\"\"\"\n",
    "    try:\n",
    "        from src.retrievers.dense.embedder import UniXcoderEmbedder\n",
    "        RetrieverFactory.register_embedder(EMBEDDER_NAME, UniXcoderEmbedder)\n",
    "    except ImportError:\n",
    "        logger.warning(\"Could not register UniXcoderEmbedder\")\n",
    "    \n",
    "    try:\n",
    "        from src.retrievers.dense.database import CodeExampleDatabase\n",
    "        RetrieverFactory.register_database(\"dense_vector\", CodeExampleDatabase)\n",
    "    except ImportError:\n",
    "        logger.warning(\"Could not register CodeExampleDatabase\")\n",
    "    \n",
    "    try:\n",
    "        from src.retrievers.fewshot_pipeline import FewShotTestGenerationPipeline\n",
    "        RetrieverFactory.register_pipeline(\"few_shot\", FewShotTestGenerationPipeline)\n",
    "    except ImportError:\n",
    "        logger.warning(\"Could not register FewShotTestGenerationPipeline\")\n",
    "\n",
    "\n",
    "# Register on module import\n",
    "_register_builtin_implementations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e016b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(file_path: str, max_examples: int = None) -> list:\n",
    "    \"\"\"\n",
    "    Load training data from JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to JSONL file\n",
    "        max_examples: Maximum number of examples to load (None = load all)\n",
    "        \n",
    "    Returns:\n",
    "        List of CodeExample objects\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    print(f\"Loading training data from: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if max_examples and i >= max_examples:\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(line.strip())\n",
    "                    \n",
    "                    # Extract focal_method and unit_test\n",
    "                    # Adjust field names based on your JSONL structure\n",
    "                    focal_method = data.get('focal_method') \n",
    "                    unit_test = data.get('unit_test') \n",
    "                    \n",
    "                    if focal_method and unit_test:\n",
    "                        example = CodeExample(\n",
    "                            focal_method=focal_method,\n",
    "                            unit_test=unit_test,\n",
    "                            metadata=data.get('metadata', {})\n",
    "                        )\n",
    "                        examples.append(example)\n",
    "                    \n",
    "                    # Progress indicator\n",
    "                    if (i + 1) % 1000 == 0:\n",
    "                        print(f\"  Loaded {i + 1} examples...\")\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"  Warning: Skipping invalid JSON at line {i + 1}\")\n",
    "                    continue\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Error: File not found: {file_path}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"✓ Loaded {len(examples)} training examples\")\n",
    "    return examples\n",
    "\n",
    "\n",
    "def load_benchmark(repo_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Load benchmark test cases from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to benchmark JSON file\n",
    "        \n",
    "    Returns:\n",
    "        List of benchmark dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        dataset = datasets.load_dataset(repo_path)\n",
    "        benchmark_rust=dataset[\"rust\"].to_list()\n",
    "        benchmark_go=dataset[\"go\"].to_list()\n",
    "        benchmark_julia=dataset[\"julia\"].to_list()\n",
    "\n",
    "        \n",
    "        return benchmark_rust, benchmark_go, benchmark_julia\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Error: File not found: {repo_path}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  Error: Invalid JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "def to_jsonable(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return [to_jsonable(o) for o in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: to_jsonable(v) for k, v in obj.items()}\n",
    "    if hasattr(obj, \"to_dict\"):\n",
    "        return obj.to_dict()\n",
    "    return obj\n",
    "\n",
    "def save_benchmark(benchmark, output_path: str):\n",
    "    \"\"\"\n",
    "    Save a generated prompt to file.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The prompt text\n",
    "        output_path: Path to save the prompt\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    jsonable_benchmark = [to_jsonable(d) for d in benchmark]\n",
    "\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for item in jsonable_benchmark:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90116ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedders': ['unixcoder'],\n",
       " 'databases': ['dense_vector'],\n",
       " 'pipelines': ['few_shot']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=RetrieverFactory()\n",
    "x.list_available_methods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c1b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = RetrieverFactory.create_full_pipeline(\n",
    "    method=EMBEDDER_NAME,\n",
    "    db_type=\"dense_vector\",\n",
    "    pipeline_type=\"few_shot\",\n",
    "    pipeline_kwargs={\n",
    "        \"top_k\": 3,\n",
    "        \"similarity_threshold\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0787c34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 2-4: Loading or Building retrieval database...\n",
      "--------------------------------------------------------------------------------\n",
      "✗ No existing database found at: data/database_index.pkl\n",
      "Building new database...\n",
      "Loading training data from: src/data/database/high-resource/method2test/reformat_test.jsonl\n",
      "  Loaded 1000 examples...\n",
      "  Loaded 2000 examples...\n",
      "  Loaded 3000 examples...\n",
      "  Loaded 4000 examples...\n",
      "  Loaded 5000 examples...\n",
      "  Loaded 6000 examples...\n",
      "  Loaded 7000 examples...\n",
      "  Loaded 8000 examples...\n",
      "  Loaded 9000 examples...\n",
      "  Loaded 10000 examples...\n",
      "  Loaded 11000 examples...\n",
      "  Loaded 12000 examples...\n",
      "  Loaded 13000 examples...\n",
      "  Loaded 14000 examples...\n",
      "  Loaded 15000 examples...\n",
      "  Loaded 16000 examples...\n",
      "  Loaded 17000 examples...\n",
      "  Loaded 18000 examples...\n",
      "  Loaded 19000 examples...\n",
      "  Loaded 20000 examples...\n",
      "  Loaded 21000 examples...\n",
      "  Loaded 22000 examples...\n",
      "  Loaded 23000 examples...\n",
      "  Loaded 24000 examples...\n",
      "  Loaded 25000 examples...\n",
      "  Loaded 26000 examples...\n",
      "  Loaded 27000 examples...\n",
      "  Loaded 28000 examples...\n",
      "  Loaded 13000 examples...\n",
      "  Loaded 14000 examples...\n",
      "  Loaded 15000 examples...\n",
      "  Loaded 16000 examples...\n",
      "  Loaded 17000 examples...\n",
      "  Loaded 18000 examples...\n",
      "  Loaded 19000 examples...\n",
      "  Loaded 20000 examples...\n",
      "  Loaded 21000 examples...\n",
      "  Loaded 22000 examples...\n",
      "  Loaded 23000 examples...\n",
      "  Loaded 24000 examples...\n",
      "  Loaded 25000 examples...\n",
      "  Loaded 26000 examples...\n",
      "  Loaded 27000 examples...\n",
      "  Loaded 28000 examples...\n",
      "  Loaded 29000 examples...\n",
      "  Loaded 30000 examples...\n",
      "  Loaded 31000 examples...\n",
      "  Loaded 32000 examples...\n",
      "  Loaded 33000 examples...\n",
      "  Loaded 34000 examples...\n",
      "  Loaded 35000 examples...\n",
      "  Loaded 36000 examples...\n",
      "  Loaded 37000 examples...\n",
      "  Loaded 38000 examples...\n",
      "  Loaded 39000 examples...\n",
      "  Loaded 40000 examples...\n",
      "  Loaded 41000 examples...\n",
      "  Loaded 42000 examples...\n",
      "  Loaded 43000 examples...\n",
      "  Loaded 44000 examples...\n",
      "  Loaded 45000 examples...\n",
      "  Loaded 46000 examples...\n",
      "  Loaded 29000 examples...\n",
      "  Loaded 30000 examples...\n",
      "  Loaded 31000 examples...\n",
      "  Loaded 32000 examples...\n",
      "  Loaded 33000 examples...\n",
      "  Loaded 34000 examples...\n",
      "  Loaded 35000 examples...\n",
      "  Loaded 36000 examples...\n",
      "  Loaded 37000 examples...\n",
      "  Loaded 38000 examples...\n",
      "  Loaded 39000 examples...\n",
      "  Loaded 40000 examples...\n",
      "  Loaded 41000 examples...\n",
      "  Loaded 42000 examples...\n",
      "  Loaded 43000 examples...\n",
      "  Loaded 44000 examples...\n",
      "  Loaded 45000 examples...\n",
      "  Loaded 46000 examples...\n",
      "  Loaded 47000 examples...\n",
      "  Loaded 48000 examples...\n",
      "  Loaded 49000 examples...\n",
      "  Loaded 50000 examples...\n",
      "  Loaded 51000 examples...\n",
      "  Loaded 52000 examples...\n",
      "  Loaded 53000 examples...\n",
      "  Loaded 54000 examples...\n",
      "  Loaded 55000 examples...\n",
      "  Loaded 56000 examples...\n",
      "  Loaded 57000 examples...\n",
      "  Loaded 58000 examples...\n",
      "  Loaded 59000 examples...\n",
      "  Loaded 60000 examples...\n",
      "  Loaded 61000 examples...\n",
      "  Loaded 62000 examples...\n",
      "  Loaded 63000 examples...\n",
      "✓ Loaded 63107 training examples\n",
      "Adding 63107 examples to database...\n",
      "  Loaded 47000 examples...\n",
      "  Loaded 48000 examples...\n",
      "  Loaded 49000 examples...\n",
      "  Loaded 50000 examples...\n",
      "  Loaded 51000 examples...\n",
      "  Loaded 52000 examples...\n",
      "  Loaded 53000 examples...\n",
      "  Loaded 54000 examples...\n",
      "  Loaded 55000 examples...\n",
      "  Loaded 56000 examples...\n",
      "  Loaded 57000 examples...\n",
      "  Loaded 58000 examples...\n",
      "  Loaded 59000 examples...\n",
      "  Loaded 60000 examples...\n",
      "  Loaded 61000 examples...\n",
      "  Loaded 62000 examples...\n",
      "  Loaded 63000 examples...\n",
      "✓ Loaded 63107 training examples\n",
      "Adding 63107 examples to database...\n",
      "Building index (this may take a few minutes)...\n",
      "Building index (this may take a few minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7889/7889 [32:43<00:00,  4.02it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database built with 63107 examples\n",
      "Saving database index...\n",
      "✓ Database saved to: data/database_index.pkl\n",
      "\n",
      "Step 5: Loading benchmark...\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Database saved to: data/database_index.pkl\n",
      "\n",
      "Step 5: Loading benchmark...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 2-4: Load or Build database index\n",
    "print(\"Steps 2-4: Loading or Building retrieval database...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check if database already exists\n",
    "if os.path.exists(DATABASE_SAVE_PATH):\n",
    "    print(f\"✓ Found existing database at: {DATABASE_SAVE_PATH}\")\n",
    "    print(\"Loading database index...\")\n",
    "    \n",
    "    try:\n",
    "        pipeline.database.load_index(DATABASE_SAVE_PATH)\n",
    "        print(f\"✓ Database loaded successfully with {pipeline.database.size} examples\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error loading database: {e}\")\n",
    "        print(\"Building new database instead...\")\n",
    "        \n",
    "        # # Load training data\n",
    "        # training_examples = load_training_data(\n",
    "        #     TRAINING_DATA_PATH,\n",
    "        #     max_examples=None  # Change to None to load all\n",
    "        # )\n",
    "        \n",
    "        # if not training_examples:\n",
    "        #     print(\"⚠ No training data loaded. Please check the file path and format.\")\n",
    "        # else:\n",
    "        #     # Build database\n",
    "        #     print(f\"Adding {len(training_examples)} examples to database...\")\n",
    "        #     pipeline.database.add_examples_bulk(training_examples)\n",
    "            \n",
    "        #     print(\"Building index (this may take a few minutes)...\")\n",
    "        #     pipeline.database.build_index()\n",
    "            \n",
    "        #     print(f\"✓ Database built with {pipeline.database.size} examples\")\n",
    "            \n",
    "        #     # Save database\n",
    "        #     os.makedirs(os.path.dirname(DATABASE_SAVE_PATH), exist_ok=True)\n",
    "        #     pipeline.database.save_index(DATABASE_SAVE_PATH)\n",
    "        #     print(f\"✓ Database saved to: {DATABASE_SAVE_PATH}\")\n",
    "else:\n",
    "    print(f\"✗ No existing database found at: {DATABASE_SAVE_PATH}\")\n",
    "    print(\"Building new database...\")\n",
    "    \n",
    "    # Load training data\n",
    "    training_examples = load_training_data(\n",
    "        TRAINING_DATA_PATH,\n",
    "        max_examples=None  # Change to None to load all\n",
    "    )\n",
    "    \n",
    "    if not training_examples:\n",
    "        print(\"⚠ No training data loaded. Please check the file path and format.\")\n",
    "    else:\n",
    "        # Build database\n",
    "        print(f\"Adding {len(training_examples)} examples to database...\")\n",
    "        pipeline.database.add_examples_bulk(training_examples)\n",
    "        \n",
    "        print(\"Building index (this may take a few minutes)...\")\n",
    "        pipeline.database.build_index()\n",
    "        \n",
    "        print(f\"✓ Database built with {pipeline.database.size} examples\")\n",
    "        \n",
    "        # Save database\n",
    "        print(\"Saving database index...\")\n",
    "        os.makedirs(os.path.dirname(DATABASE_SAVE_PATH), exist_ok=True)\n",
    "        pipeline.database.save_index(DATABASE_SAVE_PATH)\n",
    "        print(f\"✓ Database saved to: {DATABASE_SAVE_PATH}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Step 5: Load benchmark\n",
    "print(\"Step 5: Loading benchmark...\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2622b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_rust,benchmark_go,benchmark_julia = load_benchmark(BENCHMARK_REPO)\n",
    "    \n",
    "if not (benchmark_go and benchmark_rust and benchmark_julia):\n",
    "    print(\"⚠ No benchmark cases loaded. Please check the file path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193e7260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Generating prompts for benchmark cases...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate prompts for each benchmark case\n",
    "print(\"Step 6: Generating prompts for benchmark cases...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "prompts = []\n",
    "for lang in ['rust','go','julia']:\n",
    "    if lang=='rust':\n",
    "        benchmark_cases=benchmark_rust\n",
    "    elif lang=='go':\n",
    "        benchmark_cases=benchmark_go\n",
    "    else:\n",
    "        benchmark_cases=benchmark_julia\n",
    "    output_path = os.path.join(OUTPUT_DIR, EMBEDDER_NAME, lang,\"data_with_fewshot.jsonl\")\n",
    "    results=[]\n",
    "    for i, case in enumerate(benchmark_cases, 1):\n",
    "        case_id = case.get('id', f'case_{i}')\n",
    "        focal_method = case.get('focal_code')\n",
    "        \n",
    "        if not focal_method:\n",
    "            print(f\"  ⚠ Skipping case {case_id}: no focal_method found\")\n",
    "            continue\n",
    "            \n",
    "        # Generate prompt using pipeline\n",
    "        prompt = pipeline.run(focal_method)\n",
    "\n",
    "        result={\"id\":case_id,\"retrieved_context\":prompt}\n",
    "        results.append(result)\n",
    "    # Save prompt to file\n",
    "    save_benchmark(results, output_path)\n",
    "\n",
    "# print(f\"      ✓ Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933486c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
